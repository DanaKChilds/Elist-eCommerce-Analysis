{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69db2e6b",
   "metadata": {},
   "source": [
    "# Elist E-Commerce Recommendation Engine\n",
    "\n",
    "This notebook builds a Recommendation Engine to deliver personalized product suggestions for brand-new members at sign-up. Instead of waiting for browsing or purchase history, it uses information available at the time of signup (date, platform, channel, geography, loyalty status) to predict a likely first purchase and return a compact Top-K list that encourages purchase and accelerates the first order. \n",
    "\n",
    "Operationally, it runs as a simple, reliable workflow: train once, save the model, then do fast lookups whenever needed. After each run, the system automatically emails the recommendations (e.g., “Top choices for your first order”) using existing email service, so results reach the user immediately. This closes the cold-start gap in my stack, plugs cleanly into onboarding and CRM triggers, and gives the marketing/loyalty programs a measurable lever to lift revenue without heavy data collection or complex behavior tracking.\n",
    "\n",
    "To prove it moves the needle, it will launch with an A/B test: randomly split new sign-ups 50/50 into Control (standard welcome email) and Variant (same email + Top-3 recommendations). Keep send time, subject, and layout identical; only the recommendations block changes. \n",
    "\n",
    "Primary KPI: first-order conversion within 7 days. Secondary KPIs: revenue per recipient, average order value, email click-through on the recommended items, plus guardrails like unsubscribe/complaint rates. Run until it hits a reasonable sample (e.g., ~5–10k recipients or ~2 weeks, whichever comes first) to get a strong sample, and review results overall and by key segments (country, loyalty). \n",
    "\n",
    "Success would be a clear lift in conversion rate (target +3–5% or better); if positive, roll out to 100% of new users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b767376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "import joblib\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7a3bf38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  purchase_ts                 product_name purchase_platform  \\\n",
      "0    1/1/2019     Apple Airpods Headphones           website   \n",
      "1    1/1/2019  Samsung Charging Cable Pack           website   \n",
      "2    1/1/2019     Apple Airpods Headphones           website   \n",
      "\n",
      "  marketing_channel account_creation_method country_code region  \\\n",
      "0            direct                 desktop           IT   EMEA   \n",
      "1         affiliate                 unknown           US    NaN   \n",
      "2            direct                 desktop           US    NaN   \n",
      "\n",
      "   loyalty_program  \n",
      "0                0  \n",
      "1                0  \n",
      "2                0  \n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "path = r\"c:\\Users\\danac\\OneDrive - OneWorkplace\\Documents\\Elist\\Elist ML Data.csv\"\n",
    "\n",
    "keep_cols = [\n",
    "    \"PURCHASE_TS\", \"PRODUCT_NAME\", \n",
    "    \"PURCHASE_PLATFORM\", \"MARKETING_CHANNEL\",\n",
    "    \"ACCOUNT_CREATION_METHOD\", \"COUNTRY_CODE\",\n",
    "    \"Region\", \"LOYALTY_PROGRAM\"\n",
    "]\n",
    "\n",
    "data = pd.read_csv(path, usecols=keep_cols, encoding=\"utf-8-sig\")\n",
    "\n",
    "# Normalize names\n",
    "\n",
    "data.columns = (\n",
    "    data.columns.str.strip().str.lower().str.replace(\" \", \"_\", regex=False)\n",
    ")\n",
    "\n",
    "data = data.replace(r\"^\\s*$\", pd.NA, regex=True)\n",
    "print(data.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6be0b9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added time features: ['ts_year', 'ts_month']\n"
     ]
    }
   ],
   "source": [
    "# Parsing dates and feature extraction\n",
    "\n",
    "data[\"purchase_ts\"] = pd.to_datetime(data[\"purchase_ts\"], errors=\"coerce\")\n",
    "bad_ts = data[\"purchase_ts\"].isna().sum()\n",
    "if bad_ts:\n",
    "    print(\"Rows with unparseable purchase_ts (dropping):\", bad_ts)\n",
    "    data = data[~data[\"purchase_ts\"].isna()].copy()\n",
    "\n",
    "data[\"ts_year\"]  = data[\"purchase_ts\"].dt.year\n",
    "data[\"ts_month\"] = data[\"purchase_ts\"].dt.month\n",
    "print(\"Added time features:\", [\"ts_year\", \"ts_month\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1ebd4d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped rows: 0\n",
      "Rows after target/date cleaning: 108124\n"
     ]
    }
   ],
   "source": [
    "# Convert blanks to NA \n",
    "\n",
    "before = len(data)\n",
    "data = data[~data[\"product_name\"].isna()].copy()\n",
    "print(\"Dropped rows:\", before - len(data))\n",
    "\n",
    "print(\"Rows after target/date cleaning:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8519620b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features: ['ts_year', 'ts_month']\n",
      "Categorical features: ['purchase_platform', 'marketing_channel', 'account_creation_method', 'country_code', 'region', 'loyalty_program']\n",
      "X shape: (108124, 8) | Unique classes: 8\n"
     ]
    }
   ],
   "source": [
    "# Define feature sets\n",
    "\n",
    "numeric_features = [c for c in [\"ts_year\", \"ts_month\"] if c in data.columns]\n",
    "categorical_features = [c for c in [\n",
    "    \"purchase_platform\", \"marketing_channel\", \"account_creation_method\",\n",
    "    \"country_code\", \"region\", \"loyalty_program\"\n",
    "] if c in data.columns]\n",
    "\n",
    "X = data[numeric_features + categorical_features].copy()\n",
    "y = data[\"product_name\"].astype(str)\n",
    "\n",
    "print(\"Numeric features:\", numeric_features)\n",
    "print(\"Categorical features:\", categorical_features)\n",
    "print(\"X shape:\", X.shape, \"| Unique classes:\", y.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4add17d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding target\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6ddab7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((86499, 8), (21625, 8))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train / Test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_enc, test_size=0.2, random_state=42, stratify=y_enc\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f7a216f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    (\"impute\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False)),\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num\", num_pipe, numeric_features),\n",
    "    (\"cat\", cat_pipe, categorical_features),\n",
    "], remainder=\"drop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef4b540",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "I chose the Histogram-based Gradient Boosting Classifier largely because it provides predict_proba which allowed me to rank products by likelihood and optimize for top-K recommendations. This model also works great on tabular data and captures non-linear patterns and interactions between the features without the need for heavy engineering. It is also memory-effcient and handles one hot encoded categorical features as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd598696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HGB Classification Model\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"pre\", preprocess),\n",
    "    (\"clf\", HistGradientBoostingClassifier(\n",
    "        early_stopping=True,\n",
    "        validation_fraction=0.10,\n",
    "        random_state=RANDOM_STATE\n",
    "    )),\n",
    "])\n",
    "\n",
    "def top3_scorer(estimator, X, y):\n",
    "    proba = estimator.predict_proba(X)\n",
    "    return top_k_accuracy_score(y, proba, k=3)\n",
    "\n",
    "param_grid = {\n",
    "    \"clf__learning_rate\":     [0.05, 0.07, 0.09],\n",
    "    \"clf__max_iter\":          [400, 500, 600],    \n",
    "    \"clf__max_leaf_nodes\":    [12, 27, 42],\n",
    "    \"clf__min_samples_leaf\":  [1, 3, 5],\n",
    "    \"clf__l2_regularization\": [0.01, 0.02, 0.03],\n",
    "    \"clf__max_depth\":         [None]\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "\n",
    "cv = StratifiedKFold(n_splits=6, shuffle=True, random_state=RANDOM_STATE)\n",
    "gs = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring=top3_scorer,\n",
    "    refit=True,\n",
    "    cv=cv,\n",
    "    n_jobs=8,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d062a644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 243 candidates, totalling 1458 fits\n"
     ]
    }
   ],
   "source": [
    "# Fit Model\n",
    "\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774a48cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params (Top-3): {'clf__l2_regularization': 0.02, 'clf__learning_rate': 0.05, 'clf__max_depth': None, 'clf__max_iter': 400, 'clf__max_leaf_nodes': 12, 'clf__min_samples_leaf': 1}\n",
      "Best CV Top-3 accuracy: 0.9451785745537541\n",
      "Test Top-2 accuracy: 0.8205\n",
      "Test Top-3 accuracy: 0.9432\n"
     ]
    }
   ],
   "source": [
    "# Model Results\n",
    "\n",
    "print(\"Best params (Top-3):\", gs.best_params_)\n",
    "print(\"Best CV Top-3 accuracy:\", gs.best_score_)\n",
    "\n",
    "best_model = gs.best_estimator_\n",
    "y_proba = best_model.predict_proba(X_test)\n",
    "\n",
    "print(f\"Test Top-3 accuracy: {top_k_accuracy_score(y_test, y_proba, k=3):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7d011817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models\\\\recommendation_engine.joblib']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Persistence\n",
    "\n",
    "ARTIFACTS_PATH = Path(\"models/recommendation_engine.joblib\")\n",
    "ARTIFACTS_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "joblib.dump({\n",
    "    \"model\": best_model,\n",
    "    \"label_encoder\": le,\n",
    "    \"feature_cols\": list(X.columns),\n",
    "}, ARTIFACTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4877cb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "\n",
    "def recommend_topk(\n",
    "    context: dict,\n",
    "    when: str | datetime | None = None,\n",
    "    topk: int = 3,\n",
    "    artifacts_path: Path = ARTIFACTS_PATH,\n",
    "):\n",
    "    art = joblib.load(artifacts_path)\n",
    "    model = art[\"model\"]\n",
    "    le = art[\"label_encoder\"]\n",
    "    feature_cols = art[\"feature_cols\"]\n",
    "\n",
    "    # Derive time features\n",
    "    ts = pd.to_datetime(when) if when is not None else pd.Timestamp.utcnow()\n",
    "    base = {\"ts_year\": int(ts.year), \"ts_month\": int(ts.month)}\n",
    "\n",
    "    # Build one-row input\n",
    "    row = {c: base.get(c, None) for c in feature_cols}\n",
    "    for k, v in (context or {}).items():\n",
    "        if k in row:\n",
    "            row[k] = v\n",
    "    X_one = pd.DataFrame([row], columns=feature_cols)\n",
    "\n",
    "    proba = model.predict_proba(X_one)[0]\n",
    "    k = min(int(topk), len(proba))\n",
    "    top_idx = np.argsort(proba)[-k:][::-1]\n",
    "\n",
    "    labels = le.inverse_transform(top_idx)\n",
    "    scores = proba[top_idx]\n",
    "    return [(str(lbl), float(s)) for lbl, s in zip(labels, scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4d6b0548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Apple Airpods Headphones', 0.6421616021059674),\n",
       " ('27in 4k gaming monitor', 0.309085911284575),\n",
       " ('Macbook Air Laptop', 0.024213171740366413)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity Check:\n",
    "recommend_topk({\n",
    "\"purchase_platform\": \"Web\",\n",
    "\"marketing_channel\": \"Email\",\n",
    "\"account_creation_method\": \"Email\",\n",
    "\"country_code\": \"US\",\n",
    "\"region\": \"North America\",\n",
    "\"loyalty_program\": \"Yes\"\n",
    "}, when=\"2024-11-15T14:30:00Z\", topk=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
